---
title: "Logistická regresia"
output: html_notebook
---

## Logistická regresia

Predstavte si, že závislá premenná vo vašich dátach je 0 alebo 1, podľa toho, či za daných okolnosti - reprezentovaných hodnotami prediktorov $x$ nastal alebo nenastal určitý jav. Poissonovské dáta, o ktorých sme hovorili v predchádzajúcom tutoriáli, predstavujú sumár takýchto dát. "Bežný" lineárny model opäť nebude dobre fungovať, pretože uňho nemáte záruku, že bude dobre opisovať nuly a jednotky. 

**Logistická regresia** - chceme odhadovať pravdepodobnosť, že nastane nejaký jav pre určitú kombináciu hodnôt prediktorov $\mathbf{x}$. Generatívny model tu je nasledujúci:
$$
P(Y_i = 1|\mathbf{x_i}) = Bernouilli(p(\mathbf{x_i})) \\
\ln{\frac{p(\mathbf{x_i})}{1-p(\mathbf{x_i})}} = \mathbf{\beta}^T\mathbf{x_i} = \beta^{(0)} + \beta_1 x^{(1)}_1 + \dots + \beta_m x^{(m)}_i
$$
teda modelujeme logaritmus šancí (_*log odds*_), že pri daných $\mathbf{x_i}$ nastane udalosť $Y$. 

Ako ľahko vidno, predpovede modelu budú 
$$
E(Y|\mathbf{x_i}) = \frac{e^{\mathbf{\beta^Tx_i}}}{1-e^{\mathbf{\beta^Tx_i}}}
$$
teda pravdepodobnosti, že pri danom $\mathbf{x}$ nastane udalosť $Y$.

## Príklad: 

```{r}
df <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
df
```

Vysvetlivky: 

- gre - Výsledok GRE testu

- gpa - Grade Point Average - priemerný prospech

- rank - poradie "college" v rebríčku

Chceme modelovať `admit`, aby sme vedeli predpovedať, s akou pravdepodobnosťou bude daný študent prijatý. 

```{r}
summary(df)
```
Ako sa pozerať na takéto dáta? Pre faktory môžeme vytvoriť tabuľku, pre spojité preditkory môžeme kresliť podmienené priemery. 

```{r}
xtabs(~admit + rank, data = df)
```

```{r}
library(tidyverse)
ggplot(data = df, mapping = aes(x = gre, color = as.factor(admit))) + 
  geom_histogram(fill = "white", alpha = 0.6, position = "identity")
```
```{r}
df$rank <- as.factor(df$rank)
logit <- glm(admit ~ gre+gpa+rank,data=df,family="binomial")
summary(logit)
plot(logit)
```
### Interpretácia 

1. Zvýšenie GRE o 1 zvýši logaritmus šance na prijatie o 0.002, a príslušná hodnota p ukazuje, že je marginálne signifikantným faktorom prijatia.

2. Zvýšenie GPA o 1 zvýši logaritmus šance na prijatie o 0.80 a príslušná hodnota p ukazuje, že je marginálne signifikantným faktorom prijatia.

3. Interpretácia ranku je trocha odlišná: prechod z college s rankom 1 na college s rankom 2 znižuje log-šance na prijatie o -0.67 a podobne pre ďalšie prechody.

4. Rozdiel medzi základnou a reziduálnou devianciou nám hovorí, že model celkom dobre funguje.

## Predikcia

Máme uchádzača s GRE 790, GPA=3.0, a rankom 1. Aká je pravdepodobnosť, že bude prijatý?

```{r}
x <- data.frame(gre=790, gpa=3.8, rank=as.factor(1))
p <- predict(logit,x)
p
```

```{r}
library(broom)
tidy(logit)
augment(logit)
```

```{r}
df_aug <- augment(logit) %>%
  mutate(
    p_est = exp(.fitted)/(1 + exp(.fitted))
  ) %>%
  select(admit, gre, gpa, rank, p_est)
df_aug
```

```{r}
ggplot(data = df_aug, mapping = aes(x = p_est, color = as.factor(admit))) + 
  geom_histogram(fill = "white", alpha = 0.5, position = "identity")
```
```{r}
library(pROC)
aug_logit <- augment(logit) %>% mutate(p_est = exp(.fitted)/(1+exp(.fitted)))
logit_roc = roc(aug_logit$admit ~ aug_logit$p_est, plot = TRUE, print.auc = TRUE)
```

Toto nevyzerá veľmi dobre. Skúsme iné dáta.

```{r}
library(ISLR)
```


```{r}
as_tibble(Default)
```

```{r}
set.seed(42)
default_idx = sample(nrow(Default), 5000)
default_trn = Default[default_idx, ]
default_tst = Default[-default_idx, ]
```


```{r}
model_glm = glm(default ~ balance, data = default_trn, family = "binomial")
summary(model_glm)
```
```{r}
coef(model_glm)
```

```{r}
head(predict(model_glm, type = "response"))
```

```{r}
model_glm_pred = ifelse(predict(model_glm, type = "link") > 0, "Yes", "No")
```

```{r}
calc_class_err = function(actual, predicted) {
  mean(actual != predicted)
}
```

```{r}
calc_class_err(actual = default_trn$default, predicted = model_glm_pred)
```

```{r}
train_tab = table(predicted = model_glm_pred, actual = default_trn$default)
library(caret)
train_con_mat = confusionMatrix(train_tab, positive = "Yes")
c(train_con_mat$overall["Accuracy"], 
  train_con_mat$byClass["Sensitivity"], 
  train_con_mat$byClass["Specificity"])
```

```{r}
get_logistic_error = function(mod, data, res = "y", pos = 1, neg = 0, cut = 0.5) {
  probs = predict(mod, newdata = data, type = "response")
  preds = ifelse(probs > cut, pos, neg)
  calc_class_err(actual = data[, res], predicted = preds)
}
```

```{r}
get_logistic_error(model_glm, data = default_trn, 
                   res = "default", pos = "Yes", neg = "No", cut = 0.5)
```
```{r}
default_trn %>% mutate(pred = predict(model_glm, data = default_trn, type = "response")) %>%
  ggplot(mapping = aes(x = pred, color = default)) +
  geom_density(fill = "white")
```


```{r}
plot(default01 ~ balance, data = default_trn %>% mutate(default01 = ifelse(default=="Yes", 1, 0)), 
     col = "darkorange", pch = "|", ylim = c(-0.2, 1),
     main = "Using Logistic Regression for Classification")
abline(h = 0, lty = 3)
abline(h = 1, lty = 3)
abline(h = 0.5, lty = 2)
curve(predict(model_glm, data.frame(balance = x), type = "response"), 
      add = TRUE, lwd = 3, col = "dodgerblue")
abline(v = -coef(model_glm)[1] / coef(model_glm)[2], lwd = 2)
```
```{r}
model_1 = glm(default ~ 1, data = default_trn, family = "binomial")
model_2 = glm(default ~ ., data = default_trn, family = "binomial")
model_3 = glm(default ~ . ^ 2 + I(balance ^ 2),
              data = default_trn, family = "binomial")
```

```{r}
model_list = list(model_1, model_2, model_3)
train_errors = sapply(model_list, get_logistic_error, data = default_trn, 
                      res = "default", pos = "Yes", neg = "No", cut = 0.5)
test_errors  = sapply(model_list, get_logistic_error, data = default_tst, 
                      res = "default", pos = "Yes", neg = "No", cut = 0.5)
train_errors
test_errors
```
```{r}
summary(model_1)
summary(model_2)
summary(model_3)
```
```{r}
library(pROC)
test_prob = predict(model_glm, newdata = default_tst, type = "response")
test_roc = roc(default_tst$default ~ test_prob, plot = TRUE, print.auc = TRUE)
```

